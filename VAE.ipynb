{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhbI0oSTro3WhOaj9jaG/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunruL/Variational-Autoencoder/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch the Data"
      ],
      "metadata": {
        "id": "Vi_jekCpax91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!kaggle datasets download -d playlist/mnistzip\n",
        "!unzip mnistzip.zip"
      ],
      "metadata": {
        "id": "o1jSMZe9Qs9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "ZmhSl4Iia54E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "VtKXoqbiShbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creat a Custom Dataset"
      ],
      "metadata": {
        "id": "IhtlwOx1a-7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_lst: list, label_lst: list):\n",
        "        self.data_lst = data_lst\n",
        "        self.label_lst = label_lst\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_lst)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv.imread(data_lst[idx], 0)\n",
        "        image = np.expand_dims(image, axis=2)\n",
        "        image = ToTensor()(image)\n",
        "        label = label_lst[idx]\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "M980ii0JSVqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_lst = []\n",
        "label_lst = []\n",
        "for number in range(10):\n",
        "  number_lst = os.listdir('./mnist_png/train/' + str(number))\n",
        "  data_lst += ['./mnist_png/train/' + str(number) + '/' + str(file) for file in number_lst]\n",
        "  label_lst += [number for _ in range(len(number_lst))]"
      ],
      "metadata": {
        "id": "Dg1yDDxIUoE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomImageDataset(number_lst, label_lst)\n",
        "idx = 10000\n",
        "image, label = dataset[idx]\n",
        "print(label)"
      ],
      "metadata": {
        "id": "i8QE6jSLYn_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "for data in train_dataloader:\n",
        "  sample_data, sample_label = data\n",
        "  print(sample_data.shape)\n",
        "  print(sample_label.shape)"
      ],
      "metadata": {
        "id": "uXCzXBDHvHwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Neural Networks"
      ],
      "metadata": {
        "id": "ZMMp1Val8RLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Model (Encoder / recognition Model): \n",
        "\n",
        "$$q_{\\phi} (z | x)$$\n",
        "\n",
        "We use a multivariate normal distribution for it: \n",
        "\n",
        "$$q_{\\phi} (z | x) = \\mathcal{N} (\\vec{z}; \\vec{\\mu}, \\text{diag}(\\vec{\\sigma}))$$\n",
        "\n",
        "To make the the encoder differentiable, we can use the reparameterization trick: \n",
        "\n",
        "$$\\vec{\\epsilon} \\sim \\mathcal{N} (0, 1)$$\n",
        "\n",
        "$$(\\vec{\\mu}, \\log \\vec{\\sigma}) = \\text{EncoderNeuralNet}_{\\phi} (\\vec{x})$$\n",
        "\n",
        "$$\\vec{z} = \\vec{\\mu} + \\vec{\\sigma} \\odot \\vec{\\epsilon} $$\n",
        "\n",
        ", where $\\odot$ is the element-wise product."
      ],
      "metadata": {
        "id": "oDOfDkARunGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layer1 = nn.Linear(28*28, 512)\n",
        "        self.layer2 = nn.Linear(512, 256)\n",
        "        self.layer3 = nn.Linear(256, 128)\n",
        "        self.mean_layer = nn.Linear(128, 128)\n",
        "        self.log_sd_layer = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.relu(x)\n",
        "        mean = self.mean_layer(x)\n",
        "        sd = torch.exp(self.log_sd_layer(x))\n",
        "\n",
        "        # random vector from Normal distribution\n",
        "        epsilon = torch.randn_like(sd)\n",
        "        z = mean + sd * epsilon\n",
        "        return z"
      ],
      "metadata": {
        "id": "dVJawoHpyB6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()   \n",
        "        self.layer1 = nn.Linear(128, 256)\n",
        "        self.layer2 = nn.Linear(256, 512)\n",
        "        self.layer3 = nn.Linear(512, 28*28)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = self.layer1(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.layer2(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.layer3(z)\n",
        "        z = self.relu(z)\n",
        "\n",
        "        z = torch.reshape(z, (z.shape[0], 1, 28, 28))\n",
        "        return z"
      ],
      "metadata": {
        "id": "Ito1AfT26fjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_dataloader:\n",
        "  sample_data, sample_label = data\n",
        "  break"
      ],
      "metadata": {
        "id": "iRqOLW9_y1um",
        "outputId": "82f876b6-b161-4d52-b4a8-486e642471b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "z = encoder(sample_data)\n",
        "z.shape"
      ],
      "metadata": {
        "id": "g057JADL5wu4",
        "outputId": "b56b8e15-dce5-4a09-d794-f8cc6398403d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder()\n",
        "x = decoder(z)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "KDIEf0cp8zmx",
        "outputId": "e205180c-2ef2-4b60-ebee-b7666de26814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}